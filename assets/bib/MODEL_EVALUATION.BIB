% This file was created with JabRef 2.7b.
% Encoding: UTF8

@ARTICLE{Augusiak2014117,
  author = {Jacqueline Augusiak and Paul J. Van den Brink and Volker Grimm},
  title = {Merging validation and evaluation of ecological models to ‘evaludation’:
	A review of terminology and a practical approach },
  journal = {Ecological Modelling},
  year = {2014},
  volume = {280},
  pages = {117 - 128},
  number = {0},
  note = {Population Models for Ecological Risk Assessment of Chemicals},
  abstract = {Abstract Confusion about model validation is one of the main challenges
	in using ecological models for decision support, such as the regulation
	of pesticides. Decision makers need to know whether a model is a
	sufficiently good representation of its real counterpart and what
	criteria can be used to answer this question. Unclear terminology
	is one of the main obstacles to a good understanding of what model
	validation is, how it works, and what it can deliver. Therefore,
	we performed a literature review and derived a standard set of terms.
	‘Validation’ was identified as a catch-all term, which is thus useless
	for any practical purpose. We introduce the term ‘evaludation’, a
	fusion of ‘evaluation’ and ‘validation’, to describe the entire process
	of assessing a model's quality and reliability. Considering the iterative
	nature of model development, the modelling cycle, we identified six
	essential elements of evaludation: (i) ‘data evaluation’ for scrutinising
	the quality of numerical and qualitative data used for model development
	and testing; (ii) ‘conceptual model evaluation’ for examining the
	simplifying assumptions underlying a model's design; (iii) ‘implementation
	verification’ for testing the model's implementation in equations
	and as a computer programme; (iv) ‘model output verification’ for
	comparing model output to data and patterns that guided model design
	and were possibly used for calibration; (v) ‘model analysis’ for
	exploring the model's sensitivity to changes in parameters and process
	formulations to make sure that the mechanistic basis of main behaviours
	of the model has been well understood; and (vi) ‘model output corroboration’
	for comparing model output to new data and patterns that were not
	used for model development and parameterisation. Currently, most
	decision makers require ‘validating’ a model by testing its predictions
	with new experiments or data. Despite being desirable, this is neither
	sufficient nor necessary for a model to be useful for decision support.
	We believe that the proposed set of terms and its relation to the
	modelling cycle can help to make quality assessments and reality
	checks of ecological models more comprehensive and transparent.},
  doi = {http://dx.doi.org/10.1016/j.ecolmodel.2013.11.009},
  issn = {0304-3800},
  keywords = {Model validation},
  owner = {julienm},
  timestamp = {2015.01.29},
  url = {http://www.sciencedirect.com/science/article/pii/S0304380013005450}
}

@ARTICLE{BELLOCCHI2014a,
  author = {Bellocchi, Gianni and Rivington, Mike and Matthews, Keith and Acutis,
	Marco},
  title = {Deliberative processes for comprehensive evaluation of agroecological
	models. A review},
  journal = {Agronomy for Sustainable Development},
  year = {2014},
  volume = {?},
  pages = {1-17},
  abstract = {The use of biophysical models in agroecology has increased in the
	last few decades for two main reasons: the need to formalize empirical
	knowledge and the need to disseminate model-based decision support
	for decision makers (such as farmers, advisors, and policy makers).
	The first has encouraged the development and use of mathematical
	models to enhance the efficiency of field research through extrapolation
	beyond the limits of site, season, and management. The second reflects
	the increasing need (by scientists, managers, and the public) for
	simulation experimentation to explore options and consequences, for
	example, future resource use efficiency (i.e., management in sustainable
	intensification), impacts of and adaptation to climate change, understanding
	market and policy responses to shocks initiated at a biophysical
	level under increasing demand, and limited supply capacity. Production
	concerns thus dominate most model applications, but there is a notable
	growing emphasis on environmental, economic, and policy dimensions.
	Identifying effective methods of assessing model quality and performance
	has become a challenging but vital imperative, considering the variety
	of factors influencing model outputs. Understanding the requirements
	of stakeholders, in respect of model use, logically implies the need
	for their inclusion in model evaluation methods. We reviewed the
	use of metrics of model evaluation, with a particular emphasis on
	the involvement of stakeholders to expand horizons beyond conventional
	structured, numeric analyses. Two major topics are discussed: (1)
	the importance of deliberative processes for model evaluation, and
	(2) the role computer-aided techniques may play to integrate deliberative
	processes into the evaluation of agroecological models. We point
	out that (i) the evaluation of agroecological models can be improved
	through stakeholder follow-up, which is a key for the acceptability
	of model realizations in practice, (ii) model credibility depends
	not only on the outcomes of well-structured, numerically based evaluation,
	but also on less tangible factors that may need to be addressed using
	complementary deliberative processes, (iii) comprehensive evaluation
	of simulation models can be achieved by integrating the expectations
	of stakeholders via a weighting system of preferences and perception,
	(iv) questionnaire-based surveys can help understand the challenges
	posed by the deliberative process, and (v) a benefit can be obtained
	if model evaluation is conceived in a decisional perspective and
	evaluation techniques are developed at the same pace with which the
	models themselves are created and improved. Scientific knowledge
	hubs are also recognized as critical pillars to advance good modeling
	practice in relation to model evaluation (including access to dedicated
	software tools), an activity which is frequently neglected in the
	context of time-limited framework programs.},
  doi = {10.1007/s13593-014-0271-0},
  owner = {julienm},
  timestamp = {2015.01.28},
  url = {http://link.springer.com/article/10.1007/s13593-014-0271-0}
}

@ARTICLE{ORESKES_94_SCIENCE,
  author = {Oreskes, Naomi and Shrader-Frechette, Kristin and Belitz, Kenneth},
  title = {Verification, validation, and confirmation of numerical models in
	the earth sciences},
  journal = {Science},
  year = {1994},
  volume = {263},
  pages = {641-646},
  number = {5147},
  doi = {10.1126/science.263.5147.641},
  owner = {jules},
  timestamp = {2015.01.29},
  url = {http://www.sciencemag.org/content/263/5147/641}
}

